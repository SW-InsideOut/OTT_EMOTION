import numpy as np
import tensorflow as tf
import cv2
import os

# âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
MODEL_PATH = "../models/best_model_local8.h5"  # ì €ì¥í•œ ëª¨ë¸ ê²½ë¡œ
model = tf.keras.models.load_model(MODEL_PATH)

# âœ… í´ë˜ìŠ¤ ì´ë¦„ (í•™ìŠµí•  ë•Œ ì‚¬ìš©í•œ í´ë˜ìŠ¤ ìˆœì„œì™€ ë™ì¼í•´ì•¼ í•¨)
class_labels = ["Angry", "Happy", "neutral","Sad", "Surprise"]  # ì˜ˆì‹œ (ìˆ˜ì • ê°€ëŠ¥)
# âœ… ì–¼êµ´ ê²€ì¶œê¸° (Haar Cascade ì‚¬ìš©)
face_cascade = cv2.CascadeClassifier("../haarcascade_frontalface_default.xml")
profile_cascade=cv2.CascadeClassifier("../haarcascade_profileface.xml")

# âœ… í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ (ë³€ê²½ ê°€ëŠ¥)
#TEST_IMAGE_PATH = "C:\\Users\\imyy1\\Downloads\\charles-etoroma-95UF6LXe-Lo-unsplash.jpg"
#TEST_IMAGE_PATH = "C:\\Users\\imyy1\\Downloads\\1464523904287.jpg"
#í™”ë‚¨

#TEST_IMAGE_PATH ="C:\\Users\\imyy1\\Downloads\\istockphoto-176811710-612x612.jpg"
#TEST_IMAGE_PATH ="C:\\Users\\imyy1\\Downloads\\VD52317198_w640.jpg"
#TEST_IMAGE_PATH ="C:\\Users\\imyy1\\Downloads\\KlppBCGbqo.jpeg"
#TEST_IMAGE_PATH ="C:\\Users\\imyy1\\Downloads\\IMG_4128.jpeg"
#í•´í”¼
TEST_IMAGE_PATH ="C:\\Users\\imyy1\\Downloads\\gettyimages-jv11208462.jpg"
#ìŠ¬í””
#TEST_IMAGE_PATH ="C:\\Users\\imyy1\\Downloads\\images(2).jpg"
#ë¬´í‘œì •ì¸ë° ìŠ¬í””ìœ¼ë¡œ ì¸ì‹
#TEST_IMAGE_PATH ="C:\\Users\\imyy1\\Downloads\\PS18041100122.jpg"
#TEST_IMAGE_PATH ="C:\\Users\\imyy1\\Downloads\\202211171437273510_1.webp"


"""
# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # í‘ë°± ì´ë¯¸ì§€ ë¡œë“œ
    img = cv2.resize(img, (48, 48))  # ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
    img = img.astype("float32") / 255.0  # ì •ê·œí™”
    img = np.expand_dims(img, axis=-1)  # ì±„ë„ ì°¨ì› ì¶”ê°€ (48, 48, 1)
    img = np.expand_dims(img, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (1, 48, 48, 1)
    return img

# âœ… ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
processed_image = preprocess_image(TEST_IMAGE_PATH)

# âœ… ì˜ˆì¸¡ ìˆ˜í–‰
predictions = model.predict(processed_image)
predicted_class = np.argmax(predictions)  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì„ íƒ
# âœ… í™•ë¥ ì„ ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
percentage_probs = predictions * 100
# âœ… ê²°ê³¼ ì¶œë ¥
print(f"ì˜ˆì¸¡ ê²°ê³¼: {class_labels[predicted_class]}")
print("í´ë˜ìŠ¤ë³„ í™•ë¥  (ë°±ë¶„ìœ¨):")
for i, prob in enumerate(percentage_probs[0]):
    print(f"  {class_labels[i]}: {prob:.2f}%")
"""
def iou(box1, box2):
    """ ë‘ ë°•ìŠ¤ ê°„ì˜ IoU (êµì§‘í•©/í•©ì§‘í•©) ê³„ì‚° """
    x1, y1, w1, h1 = box1
    x2, y2, w2, h2 = box2

    xi1, yi1 = max(x1, x2), max(y1, y2)
    xi2, yi2 = min(x1 + w1, x2 + w2), min(y1 + h1, y2 + h2)

    inter_width = max(0, xi2 - xi1)
    inter_height = max(0, yi2 - yi1)
    intersection = inter_width * inter_height

    area1, area2 = w1 * h1, w2 * h2
    union = area1 + area2 - intersection

    return intersection / union if union > 0 else 0

def remove_duplicates(faces, iou_threshold=0.3):
    """ IoU ê¸°ë°˜ ì¤‘ë³µ ì–¼êµ´ ì œê±° """
    final_faces = []
    for face in faces:
        if all(iou(face, f) < iou_threshold for f in final_faces):
            final_faces.append(face)
    return final_faces

def detect_face_and_predict(image_path):
    """ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ê²€ì¶œí•˜ê³  ê°ì • ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ """

    # âœ… ì´ë¯¸ì§€ ë¡œë“œ ë° Grayscale ë³€í™˜
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # âœ… ì •ë©´ ì–¼êµ´ ê²€ì¶œ
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=7, minSize=(30, 30))

    # âœ… ì™¼ìª½ ì¸¡ë©´ ì–¼êµ´ ê²€ì¶œ
    profiles = profile_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=7, minSize=(30, 30))

    # âœ… ì˜¤ë¥¸ìª½ ì¸¡ë©´ ì–¼êµ´ ê²€ì¶œ (ì¢Œìš° ë°˜ì „ í›„)
    flipped_gray = cv2.flip(gray, 1)
    flipped_profiles = profile_cascade.detectMultiScale(flipped_gray, scaleFactor=1.1, minNeighbors=7, minSize=(30, 30))

    # âœ… ì˜¤ë¥¸ìª½ ì¸¡ë©´ ì–¼êµ´ ì¢Œí‘œ ë³€í™˜
    img_width = gray.shape[1]
    flipped_profiles_converted = [(img_width - x - w, y, w, h) for (x, y, w, h) in flipped_profiles]

    # âœ… ëª¨ë“  ì–¼êµ´ ì¢Œí‘œ í•©ì¹˜ê¸° (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì œê±° í›„ í•©ì¹¨)
    all_faces = []
    if len(faces) > 0:
        all_faces.extend(faces.tolist())
    if len(profiles) > 0:
        all_faces.extend(profiles.tolist())
    if len(flipped_profiles_converted) > 0:
        all_faces.extend(flipped_profiles_converted)

    # âœ… ì¤‘ë³µ ì œê±° (IoU ê¸°ì¤€)
    final_faces = remove_duplicates(all_faces)

    # âœ… ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì²˜ë¦¬
    if len(final_faces) == 0:
        print("ğŸš¨ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    # âœ… ì–¼êµ´ ê°ì • ë¶„ì„
    print(f"ğŸ“¸ ê°ì§€ëœ ì–¼êµ´ ê°œìˆ˜: {len(final_faces)}")  # ì¤‘ë³µ ì œê±° í›„ ì–¼êµ´ ê°œìˆ˜ í™•ì¸

    # âœ… ì–¼êµ´ ê°ì • ë¶„ì„
    for (x, y, w, h) in final_faces:
        # ì–¼êµ´ í¬ë¡­ ë° ì „ì²˜ë¦¬
        face = gray[y:y+h, x:x+w]
        face_resized = cv2.resize(face, (48, 48))  
        face_normalized = face_resized / 255.0  
        face_reshaped = np.expand_dims(face_normalized, axis=(0, -1))  

        # âœ… ê°ì • ì˜ˆì¸¡
        predictions = model.predict(face_reshaped)
        predicted_class = np.argmax(predictions)
        percentages = (predictions[0] * 100).round(2)  # ë°±ë¶„ìœ¨ ë³€í™˜

        # âœ… ê²°ê³¼ ì¶œë ¥
        print(f"ğŸ‘¤ ê°ì • ë¶„ì„ ê²°ê³¼: {class_labels[predicted_class]}")
        print("ğŸ“Š í´ë˜ìŠ¤ë³„ í™•ë¥  (%):")
        for label, percentage in zip(class_labels, percentages):
            print(f"  {label}: {percentage:.2f}%")

        # âœ… ì–¼êµ´ ì˜ì—­ í‘œì‹œ
        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.putText(img, class_labels[predicted_class], (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

    # âœ… ê²°ê³¼ ì´ë¯¸ì§€ ì¶œë ¥
    cv2.imshow("Emotion Detection", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    print(f"âœ… ëª¨ë¸ ì¶œë ¥ì¸µ ë…¸ë“œ ìˆ˜: {model.output_shape}")

# âœ… ì‹¤í–‰
detect_face_and_predict(TEST_IMAGE_PATH)